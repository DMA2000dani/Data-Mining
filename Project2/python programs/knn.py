# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15Ngz5mPqpHYWVrwZS9Eo1zhvTZLPEhaK
"""

import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.naive_bayes import BernoulliNB, GaussianNB, CategoricalNB, MultinomialNB
import numpy as np
from sklearn.metrics import  ConfusionMatrixDisplay,\
                  classification_report,  RocCurveDisplay, PrecisionRecallDisplay,\
                    accuracy_score, f1_score, precision_score, recall_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.tree import DecisionTreeClassifier

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
from IPython.display import display, HTML
show_html = lambda html: display(HTML(html))
from yellowbrick.classifier.rocauc import roc_auc

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("drive/MyDrive/MD/Project_2/Data/Cleaned_Dataset.csv", sep=",", encoding="UTF-8")
#df = pd.read_csv("drive/MyDrive/Cleaned_Dataset.csv", sep=",", encoding="UTF-8")
df

df = df.dropna()

cls = [str(v) for v in df['Credit_Score'].unique()]
cls

df.columns

X = df.loc[:,df.columns !="Credit_Score"]
y = df["Credit_Score"]

scaler=MinMaxScaler()
X=pd.DataFrame(scaler.fit_transform(X))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

cv=10
iter=40

knn =  KNeighborsClassifier()
scores = cross_val_score(knn,X_train,y_train,cv=10)
print("Mean accuracy: {:.2f}%".format(np.mean(scores)*100))
print("Variance: {:.4f}".format(np.var(scores)))

param = {'n_neighbors':[1, 3, 5, 7, 11, 15], 
          'weights':['distance', 'uniform'], 
          'leaf_size':[1, 5, 10, 20, 30],
          'metric': ['l2', 'l1', 'cosine']}

knn_gs =  GridSearchCV(knn,param,cv=cv, n_jobs=-1)
knn_gs.fit(X_train, y_train);

show_html(pd.DataFrame(knn_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())

knn_predictions = knn_gs.predict(X_test)
print(classification_report(knn_predictions, y_test,target_names=cls))

plt.figure(figsize=(8,8));
ConfusionMatrixDisplay.from_estimator(knn_gs, X_test,y_test, display_labels=cls, ax=plt.subplot());

results = knn_gs.cv_results_

# Crear un diccionario para almacenar la media de accuracy para cada valor de n_neighbors
mean_accuracy_dict = {}

# Iterar sobre los resultados y calcular la media de accuracy para cada valor de n_neighbors
for idx, params in enumerate(results['params']):
    n_neighbors = params['n_neighbors']
    accuracy = results['mean_test_score'][idx]
    
    if n_neighbors not in mean_accuracy_dict:
        mean_accuracy_dict[n_neighbors] = []
        
    mean_accuracy_dict[n_neighbors].append(accuracy)

# Calcular la media de accuracy para cada valor de n_neighbors
for n_neighbors, accuracy_list in mean_accuracy_dict.items():
    mean_accuracy = np.mean(accuracy_list)
    print("Valor de n_neighbors:", n_neighbors)
    print("Media de accuracy:", mean_accuracy)
    print()
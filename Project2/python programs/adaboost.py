# -*- coding: utf-8 -*-
"""Adaboost.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rV2nSxYAOXnIdpXALTu_CqG0fNOSwLm7
"""

!pip install scikit-optimize
!pip install matplotlib

import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import AdaBoostClassifier
import numpy as np
from sklearn.metrics import  ConfusionMatrixDisplay,\
                  classification_report,  RocCurveDisplay, PrecisionRecallDisplay,\
                    accuracy_score, f1_score, precision_score, recall_score
from sklearn.preprocessing import MinMaxScaler, StandardScaler

from sklearn import metrics
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
from IPython.display import display, HTML
show_html = lambda html: display(HTML(html))

from skopt import BayesSearchCV
from scipy import stats

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("drive/MyDrive/MD/Project_2/Data/Cleaned_Dataset.csv", sep=",", encoding="UTF-8").dropna()
#df = pd.read_csv("drive/MyDrive/Cleaned_Dataset.csv", sep=",", encoding="UTF-8").dropna()
df

X = df.loc[:,df.columns !="Credit_Score"]
y = df["Credit_Score"]

scaler=MinMaxScaler()
X=pd.DataFrame(scaler.fit_transform(X))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

cv=10
iter=10
random_state = 5
param = {'n_estimators': [75, 100, 125, 150, 175], 
         'algorithm': ['SAMME', 'SAMME.R'],
         'learning_rate': [0.25, 0.5,0.75,1,1.25,1.5]
        }

abc = AdaBoostClassifier(random_state = random_state)
search_abc = BayesSearchCV(abc,param,n_iter=iter, cv=cv, n_jobs=-1, refit=True, random_state=random_state);
search_abc.fit(X_train, y_train);

show_html(pd.DataFrame(search_abc.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())

abc_predictions = search_abc.predict(X_test)
print(classification_report(abc_predictions, y_test))

alpha = 0.05
n = len(abc_predictions)
mean = np.mean(abc_predictions)
std_error = stats.sem(abc_predictions)
confidence_interval = stats.t.interval(1 - alpha, n - 1, loc=mean, scale=std_error)
print("Confidence Interval:", confidence_interval)

plt.figure(figsize=(8,8));
ConfusionMatrixDisplay.from_estimator(search_abc, X_test,y_test, display_labels=abc, ax=plt.subplot());

"""# 0 is Good, 1 is Standard and 2 is Poor. The left side is the real label and the above is the predicted label"""